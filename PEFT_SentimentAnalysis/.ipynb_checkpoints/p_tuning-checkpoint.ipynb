{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for p-tuning SST-2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import get_peft_model, PrefixTuningConfig, TaskType, PromptTuningConfig, PromptTuningInit\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_name_or_path = \"t5-large\"\n",
    "tokenizer_name_or_path = \"t5-large\"\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft_config = PromptTuningConfig(\n",
    "#     task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "#     model_name_or_path=model_name_or_path,\n",
    "#     tokenizer_name_or_path=tokenizer_name_or_path,\n",
    "#     prompt_init=PromptTuningInit.TEXT,\n",
    "#     prompt_tuning_init_text=PromptTuningInit.RANDOM,\n",
    "#     num_virtual_tokens=64\n",
    "# )\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name_or_path)\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/export/arun/llmenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,582,912 || all params: 750,251,008 || trainable%: 1.677160292465745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 1024)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 1024)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 16)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-23): 23 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 1024)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 16)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-23): 23 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PrefixEncoder(\n",
       "      (embedding): Embedding(256, 49152)\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(32128, 1024)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "peft_config = PrefixTuningConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM, \n",
    "    inference_mode=False, \n",
    "    num_virtual_tokens=256\n",
    "    )\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the sst-2 dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'hide new secretions from the parental units ',\n",
       " 'label': 0,\n",
       " 'idx': 0,\n",
       " 'text_label': 'negative'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_column = \"sentence\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 384\n",
    "\n",
    "label_mapping = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "classes = dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1\n",
    ")\n",
    "\n",
    "## Add a prompt to each sentence\n",
    "# init_prompt = \"\"\"Classify the sentiment of the following sentence as positive or negative.\n",
    "# Sentence: \"\"\"\n",
    "\n",
    "# dataset = dataset.map(\n",
    "#     lambda x: {\"input_text\": [(init_prompt + text).strip() for text in x[\"sentence\"]]},\n",
    "#     batched=True,\n",
    "#     num_proc=1\n",
    "# )\n",
    "\n",
    "dataset[\"train\"][0]\n",
    "# print(dataset[\"train\"].features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2052ef5d001a45b783f8c143b7799805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cba4efc1e684a229fd006164ab0e2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091041e427bf416c969aa30770445b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_name_or_path)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = tokenizer(targets, max_length=2, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = labels[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"validation\"]\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and lr scheduler\n",
    "lr = 1e-4\n",
    "num_epochs = 5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "model.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e157731d796b4f74b14c8a3945a818f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.95904870753546</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "epoch: \u001b[1;36m0\u001b[0m loss: \u001b[1;36m4.95904870753546\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/mnt/export/arun/llmenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: \n",
       "`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you\n",
       "want to force a new download, use `force_download=True`.\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/mnt/export/arun/llmenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: \n",
       "`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you\n",
       "want to force a new download, use `force_download=True`.\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.379390929549083</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "epoch: \u001b[1;36m1\u001b[0m loss: \u001b[1;36m0.379390929549083\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21995242736667323</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "epoch: \u001b[1;36m2\u001b[0m loss: \u001b[1;36m0.21995242736667323\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19017794013483508</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "epoch: \u001b[1;36m3\u001b[0m loss: \u001b[1;36m0.19017794013483508\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18306427447660661</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "epoch: \u001b[1;36m4\u001b[0m loss: \u001b[1;36m0.18306427447660661\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.progress import Progress\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "with Progress() as progress:\n",
    "    task = progress.add_task(\"[red]Training...\", total=num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_task = progress.add_task(f\"Epoch {epoch}\", total=len(train_dataloader))\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            losses.append(loss.item())\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()        \n",
    "            progress.update(epoch_task, advance=1)\n",
    "            # progress.print(f\"loss: {loss.item()}\", end=\"\\r\")\n",
    "\n",
    "        test_task = progress.add_task(f\"Epoch {epoch}\", total=len(eval_dataloader))\n",
    "        model.eval()\n",
    "        for batch in eval_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            progress.update(test_task, advance=1)\n",
    "            # progress.print(f\"eval_loss: {loss.item()}\", end=\"\\r\")\n",
    "            \n",
    "\n",
    "        progress.update(task, advance=1)\n",
    "        progress.print(f\"epoch: {epoch} loss: {sum(losses) / len(losses)}\")\n",
    "        model.save_pretrained(\"t5-large-prefix-tuning-sst2-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"t5-large-prefix-tuning-sst2-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test on 1 sample\n",
    "\n",
    "def generate_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs)\n",
    "        \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "input = \"\"\"I Love this movie\"\"\"\n",
    "output = generate_text(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"it 's a charming and often affecting journey . \",\n",
       " 'label': 1,\n",
       " 'idx': 0,\n",
       " 'text_label': 'positive'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [00:32<00:00, 26.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "pred = []\n",
    "true = []\n",
    "for item in tqdm(dataset[\"validation\"]):\n",
    "    prompt = item[\"sentence\"]\n",
    "    output = generate_text(prompt)\n",
    "    pred.append(output)\n",
    "    true.append(item[\"text_label\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'positive'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pred)\n",
    "\n",
    "# pred = [p.lower() for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a19da1e4e0473db9aef32f4c335470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eca9eb59d6c4d94858a9369cce3c0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69df5ad413a4001be53883b148eec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e90c3994d140ae95926aac96d826f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bb59b52d5942f99596d730c0b9af2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31117d4fd3c404d9f39f82b1c93a8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043f84c23fd84579bc1aff99f75303e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/mnt/export/arun/llmenv/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "1000it [00:53, 18.76it/s]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "\n",
    "pred = []\n",
    "true = []\n",
    "\n",
    "for idx, item in tqdm(enumerate(imdb_dataset[\"test\"])):\n",
    "    text = item[\"text\"]\n",
    "    label = label_mapping[item[\"label\"]]\n",
    "    output = generate_text(text)\n",
    "    pred.append(output)\n",
    "    true.append(label)\n",
    "\n",
    "    if idx == 1000:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.926605504587156"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SST-2 VAL SET\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964035964035964"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMDB TEST SET\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/export/arun/llmenv/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for financial_phrasebank contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/financial_phrasebank\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2126e24f545c48cab6ee5b9ea062b2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470075db29de49c7937032a813c8467c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 2264\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_phrasebank = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "financial_phrasebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/mnt/export/arun/llmenv/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "2264it [02:00, 18.86it/s]\n"
     ]
    }
   ],
   "source": [
    "financial_phrasebank[\"train\"][0]\n",
    "\n",
    "for idx, item in tqdm(enumerate(financial_phrasebank[\"train\"])):\n",
    "    text = item[\"sentence\"]\n",
    "    if item[\"label\"] != 2:\n",
    "        label = label_mapping[item[\"label\"]]\n",
    "        output = generate_text(text)\n",
    "        pred.append(output)\n",
    "        true.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9291543026706232"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/export/arun/llmenv/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "true = []\n",
    "pred = []\n",
    "\n",
    "validation_output = {}\n",
    "validation_output[\"sentence\"] = []\n",
    "validation_output[\"true\"] = []\n",
    "validation_output[\"pred\"] = []\n",
    "for item in dataset[\"validation\"]:\n",
    "    input = item[\"sentence\"]\n",
    "    target = item[\"text_label\"]\n",
    "    output = generate_text(input)\n",
    "    validation_output[\"sentence\"].append(input)\n",
    "    validation_output[\"true\"].append(target)\n",
    "    validation_output[\"pred\"].append(output)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(validation_output)\n",
    "\n",
    "df.to_csv(\"t5-large-prefix-tuning-sst2_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(true, pred, labels=[\"positive\", \"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5561926605504587"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Accuracy -- Accuracy on the Validation Set\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_output = {}\n",
    "test_set_output[\"sentence\"] = []\n",
    "test_set_output[\"predicted\"] = []\n",
    "\n",
    "for item in dataset[\"test\"]:\n",
    "    input = item[\"sentence\"]\n",
    "    output = generate_text(input)\n",
    "    test_set_output[\"sentence\"].append(input)\n",
    "    test_set_output[\"predicted\"].append(output)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(test_set_output)\n",
    "df.to_csv(\"test_set_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    if row[\"true\"] != row[\"pred\"]:\n",
    "        print(row[\"sentence\"])\n",
    "        print(f\"true: {row['true']}, predicted: {row['pred']}\")\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base Model Accuracy\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name_or_path)\n",
    "model.to(device)\n",
    "\n",
    "def generate_text(text):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_length=2, do_sample=False)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# true = []\n",
    "# pred = []\n",
    "# for item in tqdm(dataset[\"validation\"]):\n",
    "#     input = item[\"sentence\"]\n",
    "#     target = item[\"text_label\"]\n",
    "#     output = generate_text(input)\n",
    "#     true.append(target)\n",
    "#     pred.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "prompt_template = \"\"\"Classify the sentiment of the given sentence as positive or negative \n",
    "sentence: {sentence} \n",
    "Answer: \"\"\"\n",
    "\n",
    "pred = []\n",
    "true = []\n",
    "\n",
    "for item in tqdm(dataset[\"validation\"]):\n",
    "    text = item[\"sentence\"]\n",
    "    prompt = prompt_template.format(sentence=text)\n",
    "    output = generate_text(prompt)\n",
    "    pred.append(output)\n",
    "    true.append(item[\"text_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset[\"validation\"][0][\"sentence\"]\n",
    "prompt = prompt_template.format(sentence=text)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**input)\n",
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map \"Fal\" to \"negative\" and \"Tru\" to \"positive\"\n",
    "\n",
    "label_mapping = {\n",
    "    \"Fal\": \"negative\",\n",
    "    \"True\": \"positive\"\n",
    "}\n",
    "\n",
    "pred = [label_mapping[item] for item in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import deepspeed\n",
    "# from rich.progress import Progress\n",
    "# from rich.console import Console\n",
    "\n",
    "# console = Console()\n",
    "\n",
    "# # Import DeepSpeed and add configuration\n",
    "# ds_config = \"ds_config.json\"  # Path to the DeepSpeed config file\n",
    "\n",
    "# # Wrap the model with DeepSpeed\n",
    "# model, optimizer, _, lr_scheduler = deepspeed.initialize(\n",
    "#     model=model,\n",
    "#     optimizer=optimizer,\n",
    "#     lr_scheduler=lr_scheduler,\n",
    "#     config=ds_config,\n",
    "#     model_parameters=model.parameters()\n",
    "# )\n",
    "\n",
    "# with Progress() as progress:\n",
    "#     train_task = progress.add_task(\"[red]Training...\", total=num_epochs)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         epoch_task = progress.add_task(f\"Epoch {epoch + 1}/{num_epochs}\", total=len(train_dataloader))\n",
    "#         model.train()\n",
    "        \n",
    "#         for step, batch in enumerate(train_dataloader):\n",
    "#             batch = {k: v.to(model.device) for k, v in batch.items()}  # Move batch to the correct device\n",
    "#             outputs = model(**batch)\n",
    "#             loss = outputs.loss\n",
    "#             model.backward(loss)   # DeepSpeed manages backward and optimizer step\n",
    "#             model.step()           # Executes DeepSpeed's step\n",
    "            \n",
    "#             progress.update(epoch_task, advance=1)\n",
    "\n",
    "#         # Evaluation step\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for step, batch in enumerate(eval_dataloader):\n",
    "#                 batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "#                 outputs = model(**batch)\n",
    "#                 eval_loss = outputs.loss\n",
    "#                 progress.update(train_task, advance=1)\n",
    "        \n",
    "#         progress.update(train_task, completed=num_epochs)\n",
    "#         model.save_checkpoint(\"sst2-t5-xl-prefix-tuning\", tag=f\"epoch_{epoch}\")\n",
    "\n",
    "#         console.log(f\"Epoch: {epoch} -- Train Loss: {loss.item()} -- Eval Loss: {eval_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
