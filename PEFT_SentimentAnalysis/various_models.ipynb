{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'hide new secretions from the parental units ',\n",
       " 'label': 0,\n",
       " 'idx': 0,\n",
       " 'text_label': 'negative'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "text_column = \"input_text\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 256\n",
    "\n",
    "label_mapping = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "classes = dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1\n",
    ")\n",
    "\n",
    "## Add a prompt to each sentence\n",
    "# init_prompt = \"\"\"Classify the sentiment of the following sentence as positive or negative.\n",
    "# Sentence: \"\"\"\n",
    "\n",
    "# dataset = dataset.map(\n",
    "#     lambda x: {\"input_text\": [(init_prompt + text).strip() for text in x[\"sentence\"]]},\n",
    "#     batched=True,\n",
    "#     num_proc=1\n",
    "# )\n",
    "\n",
    "dataset[\"train\"][0]\n",
    "# print(dataset[\"train\"].features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/export/arun/llmenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "label_mapping = {0: \"negative\", 1: \"positive\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/export/arun/llmenv/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for financial_phrasebank contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/financial_phrasebank\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "financial_phrasebank = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/mnt/export/arun/llmenv/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "2264it [03:33, 10.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "prompt_template = \"\"\"Classify the sentiment of the following sentence as \"positive\" or \"negative\".\n",
    "Sentence: {text}\n",
    "Answer: \"\"\"\n",
    "\n",
    "pred = []\n",
    "true = []\n",
    "\n",
    "for idx, item in tqdm(enumerate(financial_phrasebank[\"train\"])):\n",
    "    if item[\"label\"] != 2:\n",
    "        prompt = prompt_template.format(text=item[\"sentence\"])\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "        outputs = model.generate(**inputs)\n",
    "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        pred.append(prediction)\n",
    "        true.append(label_mapping[item[\"label\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9240759240759241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(true, pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8919716646989374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(true, pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'! Sentence: I love this movie! Sentence: I love this movie'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the sentiment of the following sentence as \"positive\" or \"negative\".\n",
    "Sentence: I love this movie!\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "outputs = model.generate(**inputs)\n",
    "prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'positive'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'positive'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {0: \"negative\", 1: \"positive\"}\n",
    "true = [label_mapping[label] for label in true]\n",
    "set(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506880733944955"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Accuracy -- Accuracy on the Validation Set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# label_mapping = {\"fal\": \"negative\", \"true\": \"positive\"}\n",
    "# pred = [label_mapping[p.lower()] for p in pred]\n",
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers==4.40.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "hf_token = \"HF_TOKEN_ID\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"google/gemma-2-2b-it\",\n",
    "    device=\"cuda\",\n",
    "    token=hf_token \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "prompt_template = \"\"\"Classify the sentiment of the given sentence as positive or negative \n",
    "sentence: {sentence} \n",
    "Answer: \"\"\"\n",
    "\n",
    "for item in tqdm(dataset[\"validation\"]):\n",
    "    text = item[\"sentence\"]\n",
    "    prompt = prompt_template.format(sentence=text)\n",
    "    output = pipe(prompt, max_length=4, num_return_sequences=1)\n",
    "    print(output)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
